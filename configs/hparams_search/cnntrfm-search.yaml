# @package _global_

# example hyperparameter optimization of some experiment with Optuna:
# python train.py -m hparams_search=mnist_optuna experiment=example

defaults:
  - override /hydra/sweeper: optuna

# choose metric which will be optimized by Optuna
# make sure this is the correct name of some metric logged in lightning module!
optimized_metric: "val/loss_best"

# here we define Optuna hyperparameter search
# it optimizes for value returned from function with @hydra.main decorator
# docs: https://hydra.cc/docs/next/plugins/optuna_sweeper
hydra:
  sweeper:
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    storage: null
    study_name: cnntrfm-search
    n_jobs: 1
    direction: minimize
    n_trials: 30

    # choose Optuna hyperparameter sampler
    # docs: https://optuna.readthedocs.io/en/stable/reference/samplers.html
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 12345
      n_startup_trials: 10 # number of random sampling runs before optimization starts
      
    params:
      model.lr: interval(1e-4, 1e-2)
      model.weight_decay: interval(0.0, 2e-1)
      model.net.out_channels: choice(64, 128, 256, 512)
      model.net.d_model: choice(64, 128, 256, 512)
      model.net.nhead: choice(4, 8)
      model.net.dim_feedforward: choice(512, 1024, 2048)
