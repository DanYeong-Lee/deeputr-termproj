{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.pardir)\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from src.datamodules.datamodule import BaseDataModule\n",
    "from src.datamodules.components.dataset import BaseDataset\n",
    "from src.models.model import BaseNet\n",
    "from src.models.components.cnn import CNN\n",
    "from src.models.components.rnn import RNN\n",
    "from src.models.components.deepfam import DeepFam\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>1h+</th>\n",
       "      <th>2h+</th>\n",
       "      <th>3h+</th>\n",
       "      <th>4h+</th>\n",
       "      <th>5h+</th>\n",
       "      <th>6h+</th>\n",
       "      <th>7h+</th>\n",
       "      <th>8h+</th>\n",
       "      <th>10h+</th>\n",
       "      <th>1h-</th>\n",
       "      <th>2h-</th>\n",
       "      <th>3h-</th>\n",
       "      <th>4h-</th>\n",
       "      <th>5h-</th>\n",
       "      <th>6h-</th>\n",
       "      <th>7h-</th>\n",
       "      <th>8h-</th>\n",
       "      <th>10h-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0_M_T1</td>\n",
       "      <td>TGTCCCCGGGTCTTCCAACGGACTGGCGTTGCCCCGGTTCACTGGG...</td>\n",
       "      <td>1.15020</td>\n",
       "      <td>1.12560</td>\n",
       "      <td>1.400500</td>\n",
       "      <td>0.23320</td>\n",
       "      <td>0.73195</td>\n",
       "      <td>-0.47038</td>\n",
       "      <td>-0.57411</td>\n",
       "      <td>-0.259830</td>\n",
       "      <td>-0.76564</td>\n",
       "      <td>0.97764</td>\n",
       "      <td>0.37349</td>\n",
       "      <td>0.13216</td>\n",
       "      <td>-1.22420</td>\n",
       "      <td>-2.991800</td>\n",
       "      <td>-3.08940</td>\n",
       "      <td>-2.58650</td>\n",
       "      <td>-2.67220</td>\n",
       "      <td>-3.33630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0_M_T1105</td>\n",
       "      <td>GCAGTGTATATAAACTTATAAATATTTCTCCAGCAAATGTGTAAAT...</td>\n",
       "      <td>3.16460</td>\n",
       "      <td>4.57390</td>\n",
       "      <td>4.277900</td>\n",
       "      <td>3.50270</td>\n",
       "      <td>2.85220</td>\n",
       "      <td>1.11460</td>\n",
       "      <td>0.42500</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>-1.01360</td>\n",
       "      <td>2.82910</td>\n",
       "      <td>2.84920</td>\n",
       "      <td>2.36750</td>\n",
       "      <td>2.32410</td>\n",
       "      <td>-0.837060</td>\n",
       "      <td>-2.51390</td>\n",
       "      <td>0.16634</td>\n",
       "      <td>-0.53467</td>\n",
       "      <td>-2.16770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0_M_T1114</td>\n",
       "      <td>ACCGGTGGATGAGGAAGGTAAATGTCTGCTCTAAGAAGTGCAGTGT...</td>\n",
       "      <td>1.20910</td>\n",
       "      <td>0.44768</td>\n",
       "      <td>1.885200</td>\n",
       "      <td>0.23320</td>\n",
       "      <td>0.45631</td>\n",
       "      <td>0.47715</td>\n",
       "      <td>0.47560</td>\n",
       "      <td>-0.420290</td>\n",
       "      <td>-0.62125</td>\n",
       "      <td>0.70201</td>\n",
       "      <td>0.83292</td>\n",
       "      <td>0.23155</td>\n",
       "      <td>0.61079</td>\n",
       "      <td>0.513920</td>\n",
       "      <td>0.13292</td>\n",
       "      <td>0.16634</td>\n",
       "      <td>-0.60179</td>\n",
       "      <td>-1.09030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0_M_T1161</td>\n",
       "      <td>CGCTACAGACAATGTCTCTGTGAGACACGTATTCGCACATGGTATC...</td>\n",
       "      <td>-3.41850</td>\n",
       "      <td>-4.45510</td>\n",
       "      <td>-3.181800</td>\n",
       "      <td>-3.57420</td>\n",
       "      <td>-4.79160</td>\n",
       "      <td>-5.27770</td>\n",
       "      <td>-5.35860</td>\n",
       "      <td>-5.507800</td>\n",
       "      <td>-6.01360</td>\n",
       "      <td>-3.54590</td>\n",
       "      <td>-4.62650</td>\n",
       "      <td>-4.64700</td>\n",
       "      <td>-5.01930</td>\n",
       "      <td>-4.972600</td>\n",
       "      <td>-5.06120</td>\n",
       "      <td>-5.57940</td>\n",
       "      <td>-5.99410</td>\n",
       "      <td>-5.32870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0_M_T117</td>\n",
       "      <td>ACAGCACAGACAGATTGACCTATTGGGGTGTTTCGCGAGTGTGAGA...</td>\n",
       "      <td>4.17190</td>\n",
       "      <td>3.92420</td>\n",
       "      <td>4.011800</td>\n",
       "      <td>3.58570</td>\n",
       "      <td>3.56590</td>\n",
       "      <td>3.01690</td>\n",
       "      <td>2.52390</td>\n",
       "      <td>2.362600</td>\n",
       "      <td>1.03080</td>\n",
       "      <td>4.35490</td>\n",
       "      <td>3.32770</td>\n",
       "      <td>3.00940</td>\n",
       "      <td>2.42590</td>\n",
       "      <td>1.381900</td>\n",
       "      <td>1.61100</td>\n",
       "      <td>1.02600</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>-0.69453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67275</th>\n",
       "      <td>S3_H_T9990</td>\n",
       "      <td>AATTAAAGAGAGAGAGAGACGGAGAACACGGTGGGTTTACTAGCGC...</td>\n",
       "      <td>1.32000</td>\n",
       "      <td>0.93303</td>\n",
       "      <td>1.614300</td>\n",
       "      <td>0.88527</td>\n",
       "      <td>0.45631</td>\n",
       "      <td>0.85155</td>\n",
       "      <td>-0.38169</td>\n",
       "      <td>-0.115440</td>\n",
       "      <td>-1.01360</td>\n",
       "      <td>1.09790</td>\n",
       "      <td>0.89705</td>\n",
       "      <td>1.02420</td>\n",
       "      <td>0.35936</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>0.34401</td>\n",
       "      <td>0.49884</td>\n",
       "      <td>0.17582</td>\n",
       "      <td>-1.43120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67276</th>\n",
       "      <td>S3_H_T9991</td>\n",
       "      <td>AAGGAATTTGTAGCGCCTGCTGACAAGTCTCTAGACTTTCTTGCCA...</td>\n",
       "      <td>2.54210</td>\n",
       "      <td>2.39860</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>2.18070</td>\n",
       "      <td>2.27450</td>\n",
       "      <td>1.24580</td>\n",
       "      <td>1.47520</td>\n",
       "      <td>0.918510</td>\n",
       "      <td>-0.42861</td>\n",
       "      <td>2.54150</td>\n",
       "      <td>2.54340</td>\n",
       "      <td>2.58980</td>\n",
       "      <td>2.05400</td>\n",
       "      <td>1.034200</td>\n",
       "      <td>1.74090</td>\n",
       "      <td>1.31820</td>\n",
       "      <td>1.19570</td>\n",
       "      <td>-1.43120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67277</th>\n",
       "      <td>S3_H_T9994</td>\n",
       "      <td>TTTGGCTATAGAATCAGGCGGCCGTTTTATGTGGGATTTGACGACC...</td>\n",
       "      <td>-2.42700</td>\n",
       "      <td>-1.45840</td>\n",
       "      <td>-0.068781</td>\n",
       "      <td>-1.25220</td>\n",
       "      <td>-0.33218</td>\n",
       "      <td>-2.69280</td>\n",
       "      <td>-1.05880</td>\n",
       "      <td>-1.507800</td>\n",
       "      <td>-5.01360</td>\n",
       "      <td>-0.22399</td>\n",
       "      <td>-0.62651</td>\n",
       "      <td>-0.86565</td>\n",
       "      <td>-2.44390</td>\n",
       "      <td>-2.001600</td>\n",
       "      <td>-4.06120</td>\n",
       "      <td>-1.26600</td>\n",
       "      <td>-1.99410</td>\n",
       "      <td>-2.53000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67278</th>\n",
       "      <td>S3_H_T9997</td>\n",
       "      <td>AGGATTTTTTTTTTCACCAATGCTCTTTAATACACACTTGCCTATA...</td>\n",
       "      <td>-0.26365</td>\n",
       "      <td>2.26850</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>1.12630</td>\n",
       "      <td>1.29580</td>\n",
       "      <td>0.24583</td>\n",
       "      <td>0.61754</td>\n",
       "      <td>-0.922790</td>\n",
       "      <td>-3.01360</td>\n",
       "      <td>0.91351</td>\n",
       "      <td>0.83292</td>\n",
       "      <td>1.13110</td>\n",
       "      <td>1.35900</td>\n",
       "      <td>-2.413300</td>\n",
       "      <td>-1.78460</td>\n",
       "      <td>-0.50088</td>\n",
       "      <td>-1.82420</td>\n",
       "      <td>-3.33630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67279</th>\n",
       "      <td>S3_H_T9999</td>\n",
       "      <td>CTGCAACCATAACTCTAATTGTAGATGTGAAGAAGATTAATGACAG...</td>\n",
       "      <td>1.26560</td>\n",
       "      <td>0.86265</td>\n",
       "      <td>1.079200</td>\n",
       "      <td>0.88527</td>\n",
       "      <td>0.73195</td>\n",
       "      <td>-0.10781</td>\n",
       "      <td>-0.79621</td>\n",
       "      <td>-2.507800</td>\n",
       "      <td>-2.42860</td>\n",
       "      <td>0.70201</td>\n",
       "      <td>0.95845</td>\n",
       "      <td>1.13110</td>\n",
       "      <td>0.92102</td>\n",
       "      <td>-1.419900</td>\n",
       "      <td>-2.10360</td>\n",
       "      <td>-0.58830</td>\n",
       "      <td>-1.99410</td>\n",
       "      <td>-4.33370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67280 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                seq      1h+  \\\n",
       "0         S0_M_T1  TGTCCCCGGGTCTTCCAACGGACTGGCGTTGCCCCGGTTCACTGGG...  1.15020   \n",
       "1      S0_M_T1105  GCAGTGTATATAAACTTATAAATATTTCTCCAGCAAATGTGTAAAT...  3.16460   \n",
       "2      S0_M_T1114  ACCGGTGGATGAGGAAGGTAAATGTCTGCTCTAAGAAGTGCAGTGT...  1.20910   \n",
       "3      S0_M_T1161  CGCTACAGACAATGTCTCTGTGAGACACGTATTCGCACATGGTATC... -3.41850   \n",
       "4       S0_M_T117  ACAGCACAGACAGATTGACCTATTGGGGTGTTTCGCGAGTGTGAGA...  4.17190   \n",
       "...           ...                                                ...      ...   \n",
       "67275  S3_H_T9990  AATTAAAGAGAGAGAGAGACGGAGAACACGGTGGGTTTACTAGCGC...  1.32000   \n",
       "67276  S3_H_T9991  AAGGAATTTGTAGCGCCTGCTGACAAGTCTCTAGACTTTCTTGCCA...  2.54210   \n",
       "67277  S3_H_T9994  TTTGGCTATAGAATCAGGCGGCCGTTTTATGTGGGATTTGACGACC... -2.42700   \n",
       "67278  S3_H_T9997  AGGATTTTTTTTTTCACCAATGCTCTTTAATACACACTTGCCTATA... -0.26365   \n",
       "67279  S3_H_T9999  CTGCAACCATAACTCTAATTGTAGATGTGAAGAAGATTAATGACAG...  1.26560   \n",
       "\n",
       "           2h+       3h+      4h+      5h+      6h+      7h+       8h+  \\\n",
       "0      1.12560  1.400500  0.23320  0.73195 -0.47038 -0.57411 -0.259830   \n",
       "1      4.57390  4.277900  3.50270  2.85220  1.11460  0.42500  0.015806   \n",
       "2      0.44768  1.885200  0.23320  0.45631  0.47715  0.47560 -0.420290   \n",
       "3     -4.45510 -3.181800 -3.57420 -4.79160 -5.27770 -5.35860 -5.507800   \n",
       "4      3.92420  4.011800  3.58570  3.56590  3.01690  2.52390  2.362600   \n",
       "...        ...       ...      ...      ...      ...      ...       ...   \n",
       "67275  0.93303  1.614300  0.88527  0.45631  0.85155 -0.38169 -0.115440   \n",
       "67276  2.39860  2.562500  2.18070  2.27450  1.24580  1.47520  0.918510   \n",
       "67277 -1.45840 -0.068781 -1.25220 -0.33218 -2.69280 -1.05880 -1.507800   \n",
       "67278  2.26850  2.310000  1.12630  1.29580  0.24583  0.61754 -0.922790   \n",
       "67279  0.86265  1.079200  0.88527  0.73195 -0.10781 -0.79621 -2.507800   \n",
       "\n",
       "          10h+      1h-      2h-      3h-      4h-       5h-      6h-  \\\n",
       "0     -0.76564  0.97764  0.37349  0.13216 -1.22420 -2.991800 -3.08940   \n",
       "1     -1.01360  2.82910  2.84920  2.36750  2.32410 -0.837060 -2.51390   \n",
       "2     -0.62125  0.70201  0.83292  0.23155  0.61079  0.513920  0.13292   \n",
       "3     -6.01360 -3.54590 -4.62650 -4.64700 -5.01930 -4.972600 -5.06120   \n",
       "4      1.03080  4.35490  3.32770  3.00940  2.42590  1.381900  1.61100   \n",
       "...        ...      ...      ...      ...      ...       ...      ...   \n",
       "67275 -1.01360  1.09790  0.89705  1.02420  0.35936 -0.008894  0.34401   \n",
       "67276 -0.42861  2.54150  2.54340  2.58980  2.05400  1.034200  1.74090   \n",
       "67277 -5.01360 -0.22399 -0.62651 -0.86565 -2.44390 -2.001600 -4.06120   \n",
       "67278 -3.01360  0.91351  0.83292  1.13110  1.35900 -2.413300 -1.78460   \n",
       "67279 -2.42860  0.70201  0.95845  1.13110  0.92102 -1.419900 -2.10360   \n",
       "\n",
       "           7h-      8h-     10h-  \n",
       "0     -2.58650 -2.67220 -3.33630  \n",
       "1      0.16634 -0.53467 -2.16770  \n",
       "2      0.16634 -0.60179 -1.09030  \n",
       "3     -5.57940 -5.99410 -5.32870  \n",
       "4      1.02600  0.70633 -0.69453  \n",
       "...        ...      ...      ...  \n",
       "67275  0.49884  0.17582 -1.43120  \n",
       "67276  1.31820  1.19570 -1.43120  \n",
       "67277 -1.26600 -1.99410 -2.53000  \n",
       "67278 -0.50088 -1.82420 -3.33630  \n",
       "67279 -0.58830 -1.99410 -4.33370  \n",
       "\n",
       "[67280 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2h-', '3h-', '4h-', '5h-', '6h-', '7h-', '8h-', '10h-'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "a = \"[0,1,2,3,4]\"\n",
    "json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = BaseNet(CNN())\n",
    "net.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Transformer.generate_square_subsequent_mask(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "train_dataset = BaseDataset(df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, init_level, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 4,\n",
    "        out_dim: int = 256,\n",
    "        kernel_size: int = 9,\n",
    "        pool_size: int = 3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=out_dim, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(pool_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (N, C, L)\n",
    "        \n",
    "        return self.main(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_sizes: List = [6, 9, 12, 15],\n",
    "        out_channels: int = 256,\n",
    "        pool_size: int = 3\n",
    "    ):\n",
    "        super().__init__() \n",
    "        self.conv_blocks = nn.ModuleList([ConvBlock(4, out_channels, k, pool_size) for k in kernel_sizes])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (N, L, C)\n",
    "        x = x.transpose(1, 2)  # (N, C, L)\n",
    "        conv_outs = []\n",
    "        for conv in self.conv_blocks:\n",
    "            conv_outs.append(conv(x))\n",
    "        x = torch.cat(conv_outs, dim=1)  # (N, C, L)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TRFMDecode(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_sizes: List = [6, 9, 12, 15],\n",
    "        out_channels: int = 256,\n",
    "        pool_size: int = 3,\n",
    "        d_model: int = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.fc1 = nn.Linear(len(kernel_sizes) * out_channels, d_model)\n",
    "        self.decoder = nn.TransformerDecoderLayer(d_model=d_model, nhead=8, dim_feedforward=2048)\n",
    "        self.embed_tgt = nn.Linear(1, d_model)\n",
    "        self.out = nn.Linear(d_model, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, init_level):\n",
    "        # x: (N, L, C)\n",
    "        x = self.encoder(x)  # (N, C, L)\n",
    "        x = x.transpose(1, 2)  # (N, L, C)\n",
    "        x = self.fc1(x)  # (N, L, d_model)\n",
    "        x = x.transpose(0, 1)  # (L, N, d_model)\n",
    "        tgt = self.embed_tgt(init_level.unsqueeze(-1))  # (N, d_model)\n",
    "        tgt = tgt.unsqueeze(0)  # (1, N, d_model)\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(8):\n",
    "            tgt = self.decoder(tgt, x)  # (L, N, d_model)\n",
    "            out = self.out(tgt[-1]) # (N, 1)\n",
    "            outputs.append(out)\n",
    "            next_tgt = self.embed_tgt(out).unsqueeze(0)  # (1, N, d_model)\n",
    "            tgt = torch.cat([tgt, next_tgt], axis=0)  # (L+1, N, d_model)\n",
    "        \n",
    "        outputs = torch.cat(outputs, axis=1)  # (N, 8)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 8])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TRFMDecode()\n",
    "net(X, init_level).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 8])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_level.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 256])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Linear(1, 256)\n",
    "tgt = init_level.unsqueeze(-1)\n",
    "tgt = embed(tgt).unsqueeze(0)\n",
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 256])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Encoder()\n",
    "decoder = nn.TransformerDecoderLayer(d_model=256, nhead=8, dim_feedforward=2048)\n",
    "memory = torch.randn((30, 96, 256))\n",
    "decoder(tgt, memory)[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size: int = 9,\n",
    "        out_channels: int = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=4, out_channels=out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(110 - kernel_size + 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (N, C, L)\n",
    "        return self.conv(x).squeeze(-1)\n",
    "\n",
    "    \n",
    "class DeepDecode_v2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_sizes: List[int] = [6, 9, 12, 15],\n",
    "        out_channels: int = 256,\n",
    "        embed_dim: int = 256,\n",
    "        fc_dim: List[int] = [1024, 64],\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv_blocks = nn.ModuleList([ConvBlock(i, out_channels) for i in kernel_sizes])\n",
    "        self.embed = nn.Linear(len(kernel_sizes) * out_channels, embed_dim)\n",
    "        self.gru_cell = nn.GRUCell(1, embed_dim)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(embed_dim, fc_dim[0]),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_dim[0], fc_dim[1]),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_dim[1], 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, init_level):\n",
    "        # x: (N, L, C)\n",
    "        x = x.transpose(1, 2)\n",
    "        temp = []\n",
    "        for conv in self.conv_blocks:\n",
    "            temp.append(conv(x))\n",
    "        x = torch.cat(temp, axis=1)\n",
    "        h = self.embed(x)\n",
    "        \n",
    "        outputs = []\n",
    "        out = init_level.unsqueeze(1)\n",
    "        for _ in range(8):\n",
    "            h = self.gru_cell(out, h)\n",
    "            out = self.out(h)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return torch.cat(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 8])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = DeepDecode_v2()\n",
    "emb = net(X, init_level)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_cell = nn.GRUCell(256, 256)\n",
    "gru_cell(emb).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dream",
   "language": "python",
   "name": "dream"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
